# NOM ET PRENOME : YASSINE CHARIFI 
# Code ApogÃ©e : 22006473
![image](https://github.com/charifiiyassineencg-dotcom/DS_2025/blob/main/WhatsApp%20Image%202026-01-05%20at%2014.14.55.jpeg)
# ğŸ“˜ **RAPPORT DESCRIPTIF â€“ PROJET DATA SCIENCE**

## *Dataset : Diabetes Progression (RÃ©gression)*

---

## **1. Contexte & Objectif du Projet**

Le dataset **Diabetes** fourni par *Scikit-Learn* est un jeu de donnÃ©es de rÃ©fÃ©rence en Data Science.
Il permet de **prÃ©dire la progression quantitative du diabÃ¨te** chez des patients Ã  partir de mesures cliniques normalisÃ©es.

Contrairement Ã  un problÃ¨me de classification, la variable cible est **continue**, ce qui place ce projet dans un cadre de **rÃ©gression supervisÃ©e**.

### ğŸ¯ **Objectif principal**

Construire une chaÃ®ne complÃ¨te de Machine Learning permettant de :

1. Charger et inspecter le dataset
2. Simuler un cas rÃ©el avec des donnÃ©es manquantes
3. Nettoyer et prÃ©parer les donnÃ©es
4. RÃ©aliser une analyse exploratoire (EDA)
5. Construire un modÃ¨le de rÃ©gression
6. Ã‰valuer sa performance

---

## **2. Les DonnÃ©es (X et y)**

### ğŸ”¹ Variables explicatives (X)

Le dataset contient **10 variables cliniques normalisÃ©es**, notamment :

* age â€“ Ã¢ge du patient
* bmi â€“ indice de masse corporelle
* bp â€“ pression sanguine
* s1 Ã  s6 â€“ mesures sÃ©riques liÃ©es au mÃ©tabolisme

Ces variables sont centrÃ©es et mises Ã  lâ€™Ã©chelle, ce qui facilite lâ€™apprentissage du modÃ¨le.

### ğŸ”¹ Variable cible (y)

* **Progression du diabÃ¨te** aprÃ¨s un an
* Variable **continue** (rÃ©gression)

â¡ï¸ Le dataset contient **442 observations** et **11 colonnes (10 features + 1 target)**.

---

## **3. Simulation de DonnÃ©es Manquantes (RÃ©alisme du Projet)**

Dans un contexte rÃ©el, les donnÃ©es mÃ©dicales sont souvent incomplÃ¨tes.
Pour simuler ce scÃ©nario :

* **5% de valeurs manquantes** ont Ã©tÃ© introduites artificiellement
* Uniquement dans les variables explicatives (X)
* La variable cible a Ã©tÃ© prÃ©servÃ©e

ğŸ‘‰ Cette Ã©tape permet de tester la robustesse du pipeline face Ã  des donnÃ©es imparfaites.

---

## **4. Nettoyage & Imputation**

### ğŸ”§ StratÃ©gie utilisÃ©e

```python
SimpleImputer(strategy='mean')
```

Pour chaque feature :

* Calcul de la moyenne
* Remplacement des valeurs manquantes par cette moyenne

ğŸ”¹ RÃ©sultat :
**Aucune valeur manquante restante** aprÃ¨s lâ€™imputation.

ğŸ“Œ *Note mÃ©thodologique*
Dans un contexte industriel strict, lâ€™imputation serait rÃ©alisÃ©e **aprÃ¨s le train/test split** afin dâ€™Ã©viter toute fuite de donnÃ©es (*data leakage*).

---

## **5. Analyse Exploratoire (EDA)**

### ğŸ“Š Statistiques descriptives

Lâ€™analyse statistique rÃ©vÃ¨le :

* Des variables bien centrÃ©es autour de 0
* Des dispersions diffÃ©rentes selon les mesures
* Certaines variables plus informatives que dâ€™autres

### ğŸ“‰ Distribution de la variable BMI

Le BMI prÃ©sente :

* Une distribution relativement symÃ©trique
* Une influence notable sur la progression du diabÃ¨te

Cette variable est reconnue comme **cliniquement pertinente**.

### ğŸ”¥ Matrice de corrÃ©lation

Lâ€™analyse de corrÃ©lation montre que :

* **bmi**, **bp** et certaines variables sÃ©riques sont fortement corrÃ©lÃ©es Ã  la cible
* Peu de corrÃ©lations extrÃªmes entre features â†’ faible redondance

---

## **6. MÃ©thodologie de Split (Train/Test)**

```python
train_test_split(test_size=0.2, random_state=42)
```

* **Train** : 80% des donnÃ©es
* **Test** : 20% des donnÃ©es

âœ”ï¸ Ce ratio permet :

* Un apprentissage stable
* Une Ã©valuation fiable

Le paramÃ¨tre `random_state=42` garantit la **reproductibilitÃ©**.

---

## **7. ModÃ©lisation : Random Forest Regressor**

### Pourquoi un Random Forest Regressor ?

* Excellente performance sur des relations non linÃ©aires
* Peu sensible aux outliers
* Capture les interactions complexes entre variables
* Robuste face au bruit

### ParamÃ¨tres principaux

* `n_estimators = 100`
* `random_state = 42`

Le modÃ¨le apprend Ã  approximer la progression du diabÃ¨te Ã  partir des signaux cliniques.

---

## **8. Ã‰valuation du ModÃ¨le**

### ğŸ“ MÃ©triques utilisÃ©es

* **Mean Squared Error (MSE)**
  â†’ mesure lâ€™erreur moyenne entre valeurs rÃ©elles et prÃ©dites

* **RÂ² Score**
  â†’ proportion de la variance expliquÃ©e par le modÃ¨le

### ğŸ“Š RÃ©sultats observÃ©s

* **MSE modÃ©rÃ©**, indiquant des erreurs contrÃ´lÃ©es
* **RÂ² â‰ˆ 0.45 â€“ 0.50**, valeur cohÃ©rente pour un problÃ¨me mÃ©dical rÃ©el

### ğŸ“ˆ Visualisation PrÃ©dictions vs RÃ©alitÃ©

Le nuage de points montre :

* Une tendance linÃ©aire claire
* Une dispersion attendue pour des donnÃ©es biomÃ©dicales
* Un modÃ¨le globalement bien calibrÃ©

---

## **9. Conclusion GÃ©nÃ©rale**

Ce projet dÃ©montre la mise en Å“uvre complÃ¨te dâ€™un **pipeline de Data Science appliquÃ© Ã  un problÃ¨me rÃ©el de rÃ©gression** :

1. Chargement des donnÃ©es
2. Simulation de donnÃ©es manquantes
3. Nettoyage et imputation
4. Analyse exploratoire approfondie
5. SÃ©paration mÃ©thodologique
6. ModÃ©lisation robuste
7. Ã‰valuation pertinente

ğŸ“ **CompÃ©tences validÃ©es**

* Data cleaning & preprocessing
* Analyse exploratoire
* Gestion des valeurs manquantes
* RÃ©gression supervisÃ©e
* InterprÃ©tation de mÃ©triques
* Visualisation des performances

Le dataset **Diabetes** constitue un excellent cas dâ€™Ã©tude pour comprendre les limites et les enjeux de la prÃ©diction mÃ©dicale en Machine Learning.
