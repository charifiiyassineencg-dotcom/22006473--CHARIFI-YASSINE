NOM : CHARIFI YASSINE
Code ApogÃ©e : 22006473

# ğŸ“Š Projet de PrÃ©diction â€“ Dataset Diabetes

## Description du projet

Ce projet a pour objectif de **prÃ©dire les valeurs de progression du diabÃ¨te** chez des patients Ã  partir de diffÃ©rentes variables cliniques. Le projet suit lâ€™ensemble du **cycle de vie dâ€™un projet de Data Science**, depuis lâ€™importation des donnÃ©es jusquâ€™Ã  lâ€™Ã©valuation du modÃ¨le de Machine Learning.

---

## ğŸ”§ Technologies et BibliothÃ¨ques UtilisÃ©es

* Python 3.x
* Pandas, NumPy pour la manipulation des donnÃ©es
* Matplotlib, Seaborn pour la visualisation
* Scikit-Learn pour le Machine Learning et les mÃ©triques

---

## ğŸ“‚ Structure du projet

```text
â”œâ”€â”€ data/
â”‚   â””â”€â”€ diabetes.csv         # Dataset (optionnel)
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ diabetes_regression.ipynb  # Notebook principal
â”œâ”€â”€ src/
â”‚   â””â”€â”€ preprocessing.py     # Scripts de nettoyage et prÃ©paration
â”œâ”€â”€ README.md                # Ce fichier
â””â”€â”€ requirements.txt         # BibliothÃ¨ques nÃ©cessaires
```

---

## âš™ï¸ Ã‰tapes du projet

### 1. Importation des bibliothÃ¨ques

Toutes les bibliothÃ¨ques nÃ©cessaires pour le traitement de donnÃ©es, visualisation et Machine Learning ont Ã©tÃ© importÃ©es.

### 2. Chargement des donnÃ©es

Le dataset utilisÃ© est `load_diabetes` de Scikit-Learn. Il contient des informations cliniques sur des patients et une variable cible continue reprÃ©sentant la progression du diabÃ¨te.

### 3. Simulation de donnÃ©es manquantes

Pour simuler un scÃ©nario rÃ©aliste, 5% des valeurs des features ont Ã©tÃ© remplacÃ©es par des `NaN`.

### 4. Nettoyage et prÃ©paration des donnÃ©es

* SÃ©paration des features (`X`) et de la cible (`y`)
* Imputation des valeurs manquantes par la **moyenne**
* Conversion en DataFrame pour conserver les noms des colonnes

### 5. Analyse exploratoire (EDA)

* Statistiques descriptives
* Distribution dâ€™une feature clÃ© (`bmi`)
* Matrice de corrÃ©lation (top 10 features)

### 6. SÃ©paration Train / Test

* 80% des donnÃ©es pour lâ€™entraÃ®nement
* 20% pour le test

### 7. ModÃ©lisation

* ModÃ¨le utilisÃ© : **Random Forest Regressor**
* EntraÃ®nement sur les donnÃ©es dâ€™entraÃ®nement

### 8. Ã‰valuation du modÃ¨le

* MÃ©triques utilisÃ©es :

  * **Mean Squared Error (MSE)** : mesure lâ€™erreur moyenne quadratique
  * **R-squared (RÂ²)** : coefficient de dÃ©termination
* Visualisation des prÃ©dictions vs valeurs rÃ©elles

---

## ğŸ“ˆ RÃ©sultats

* **Mean Squared Error (MSE)** : `afficher la valeur obtenue`
* **R-squared (RÂ²)** : `afficher la valeur obtenue`

**Graphique : PrÃ©dictions vs RÃ©alitÃ©**

![PrÃ©dictions vs RÃ©alitÃ©](https://via.placeholder.com/600x400?text=Graph+Predictions+vs+Reality)

---

## ğŸ’¡ Conclusion

Le modÃ¨le Random Forest Regressor permet de prÃ©dire la progression du diabÃ¨te avec un **niveau de prÃ©cision raisonnable** sur ce dataset.
Le projet illustre les bonnes pratiques de Data Science :

* PrÃ©-traitement des donnÃ©es
* Analyse exploratoire
* SÃ©paration Train/Test
* Ã‰valuation du modÃ¨le

---

## ğŸ“Œ Pour aller plus loin

* Tester dâ€™autres modÃ¨les de rÃ©gression (Lasso, Ridge, Gradient Boosting)
* Optimiser les hyperparamÃ¨tres avec `GridSearchCV`
* Ajouter des techniques avancÃ©es de feature engineering
* DÃ©ployer le modÃ¨le avec **Streamlit** ou **Flask**




